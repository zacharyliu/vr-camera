<!DOCTYPE html>

<html lang="en">
<head>
<title>Web VR boilerplate</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0, shrink-to-fit=no">
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<link rel="manifest" href="/manifest.json">
<style>
body {
  width: 100%;
  height: 100%;
  background-color: #000;
  color: #fff;
  margin: 0px;
  padding: 0;
  overflow: hidden;
}
</style>
</head>

<body>

</body>

<script>
/*
 * Debug parameters.
 */
WebVRConfig = {
  /**
   * webvr-polyfill configuration
   */

  // Forces availability of VR mode.
  FORCE_ENABLE_VR: true, // Default: false.
  // Complementary filter coefficient. 0 for accelerometer, 1 for gyro.
  //K_FILTER: 0.98, // Default: 0.98.
  // How far into the future to predict during fast motion.
  //PREDICTION_TIME_S: 0.040, // Default: 0.040 (in seconds).
  // Flag to disable touch panner. In case you have your own touch controls
  //TOUCH_PANNER_DISABLED: true, // Default: false.
  // Enable yaw panning only, disabling roll and pitch. This can be useful for
  // panoramas with nothing interesting above or below.
  //YAW_ONLY: true, // Default: false.

  /**
   * webvr-boilerplate configuration
   */
  // Forces distortion in VR mode.
  //FORCE_DISTORTION: true, // Default: false.
  // Override the distortion background color.
  // DISTORTION_BGCOLOR: {x: 1, y: 0, z: 0, w: 1}, // Default: (0,0,0,1).
  // Prevent distortion from happening.
  //PREVENT_DISTORTION: true, // Default: false.
  // Show eye centers for debugging.
  // SHOW_EYE_CENTERS: true, // Default: false.
  // Prevent the online DPDB from being fetched.
  // NO_DPDB_FETCH: true,  // Default: false.
};
</script>

<!--
  A polyfill for Promises. Needed for IE and Edge.
  -->
<script src="bower_components/promise-polyfill/Promise.min.js"></script>

<!--
  three.js 3d library
  -->
<script src="bower_components/threejs/build/three.js"></script>

<!--
  VRControls.js acquires positional information from connected VR devices and applies the transformations to a three.js camera object.
   -->
<script src="bower_components/threejs/examples/js/controls/VRControls.js"></script>

<!--
  VREffect.js handles stereo camera setup and rendering.
  -->
<script src="bower_components/threejs/examples/js/effects/VREffect.js"></script>

<!--
  A polyfill for WebVR using the Device{Motion,Orientation}Event API.
  -->
<script src="bower_components/webvr-polyfill/build/webvr-polyfill.js"></script>

<!--
  Helps enter and exit VR mode, provides best practices while in VR.
  -->
<script src="build/webvr-manager.js"></script>


<script>
// Setup three.js WebGL renderer. Note: Antialiasing is a big performance hit.
// Only enable it if you actually need to.
var renderer = new THREE.WebGLRenderer({antialias: true});
renderer.setPixelRatio(window.devicePixelRatio);

// Append the canvas element created by the renderer to document body element.
document.body.appendChild(renderer.domElement);

// Create a three.js scene.
var scene = new THREE.Scene();

// Create a three.js camera.
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);

// Apply VR stereo rendering to renderer.
var effect = new THREE.VREffect(renderer);
effect.setSize(window.innerWidth, window.innerHeight);


// Create a VR manager helper to enter and exit VR mode.
var params = {
  hideButton: false, // Default: false.
  isUndistorted: false // Default: false.
};
var manager = new WebVRManager(renderer, effect, params);


// Load canvas to display streaming video
// Source: http://www.sitepoint.com/streaming-a-raspberry-pi-camera-into-vr-with-javascript/
var canvas = document.createElement('canvas');
canvas.width = 512;
canvas.height = 512;

var context = canvas.getContext('2d');
var texture = new THREE.Texture(canvas);
texture.context = context;

var cameraPlane = new THREE.PlaneGeometry(512, 512/(4/3));

var cameraMesh = new THREE.Mesh(cameraPlane, new THREE.MeshBasicMaterial({
  color: 0xffffff, opacity: 1, map: texture
}));
cameraMesh.position.z = -300;

scene.add(cameraMesh);


// Request animation frame loop function
var lastRender = 0;
function animate(timestamp) {
  var delta = Math.min(timestamp - lastRender, 500);
  lastRender = timestamp;

  // Update video stream
  // Source: http://www.sitepoint.com/streaming-a-raspberry-pi-camera-into-vr-with-javascript/
  var piImage = new Image();
  piImage.onload = function() {
    context.drawImage(piImage, 0, 0, canvas.width, canvas.height);
    texture.needsUpdate = true;

    // Render the scene through the manager.
    manager.render(scene, camera, timestamp);

    requestAnimationFrame(animate);
  }
  piImage.crossOrigin = "anonymous";
  piImage.src = "http://10.8.138.54:8080/shot.jpg?time=" + new Date().getTime();
}

// Kick off animation loop
animate(performance ? performance.now() : Date.now());

</script>

</html>
